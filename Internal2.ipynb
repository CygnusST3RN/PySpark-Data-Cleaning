{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c61c16e-fb08-41b3-bf9b-e24117605ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, mean, to_date, to_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18c23f0d-021c-499e-835e-6bbbd9416584",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Internal2\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "529555c2-5ca3-410d-9dac-7c8b6658dace",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"Datasets/Sales Data.csv\"\n",
    "\n",
    "sales_df = spark.read.csv(csv_path, header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33b2d661-2898-48c9-a997-2fbc193efe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 06:05:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/aRKNitro/Tutorials/Datasets/Sales%20Data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column _c0 has 0 null values\n",
      "Column Order ID has 0 null values\n",
      "Column Product has 0 null values\n",
      "Column Quantity Ordered has 0 null values\n",
      "Column Price Each has 0 null values\n",
      "Column Order Date has 0 null values\n",
      "Column Purchase Address has 0 null values\n",
      "Column Month has 0 null values\n",
      "Column Sales has 3 null values\n",
      "Column City has 0 null values\n",
      "Column Hour has 0 null values\n"
     ]
    }
   ],
   "source": [
    "for cols in sales_df.columns:\n",
    "    null_cnt = sales_df.filter(col(cols).isNull()).count()\n",
    "    print(f\"Column {cols} has {null_cnt} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "550ca05a-76e3-4a9c-bf8d-83c6def78b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sales_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee4faa95-188b-4c59-908e-7c8ae185c87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg(Sales)=185.49375999620437)]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(mean(\"Sales\")).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0d39212a-8043-45d2-ac53-ae99c6ff9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna({\"Sales\": df.select(mean(\"Sales\")).collect()[0][0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "980f5ec1-aeac-47c4-b705-e16c552e67a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 06:05:21 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/aRKNitro/Tutorials/Datasets/Sales%20Data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column _c0 has 0 null values\n",
      "Column Order ID has 0 null values\n",
      "Column Product has 0 null values\n",
      "Column Quantity Ordered has 0 null values\n",
      "Column Price Each has 0 null values\n",
      "Column Order Date has 0 null values\n",
      "Column Purchase Address has 0 null values\n",
      "Column Month has 0 null values\n",
      "Column Sales has 0 null values\n",
      "Column City has 0 null values\n",
      "Column Hour has 0 null values\n"
     ]
    }
   ],
   "source": [
    "for cols in df.columns:\n",
    "    null_cnt = df.filter(col(cols).isNull()).count()\n",
    "    print(f\"Column {cols} has {null_cnt} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "999f208a-9845-492d-a6a6-45de9c53312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "31fd6fae-25a9-4f04-b827-ac140286a164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Sales: double (nullable = false)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aba70644-c7e5-425d-a4da-680dd68d763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Correctly parse Order Date in dd-MM-yyyy HH:mm format\n",
    "df = df.withColumn(\"Order Date\", to_date(\"Order Date\", \"dd-MM-yyyy HH:mm\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f980aa8d-1472-4c4a-8bc8-6f5bfa3a63c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 06:05:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      " Schema: _c0, Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/aRKNitro/Tutorials/Datasets/Sales%20Data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Order Date|\n",
      "+----------+\n",
      "|2019-12-31|\n",
      "|2019-12-29|\n",
      "|2019-12-10|\n",
      "|2019-12-11|\n",
      "|2019-12-24|\n",
      "|2019-12-10|\n",
      "|2019-12-09|\n",
      "|2019-12-16|\n",
      "|2019-12-18|\n",
      "|2019-12-19|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Order Date\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e127c7b6-7ed3-428d-bca7-6e8bfaf7075c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Order ID: integer (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: date (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- Sales: double (nullable = false)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Hour: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5504b712-c2e0-43f4-9770-f87f8f5d90be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 06:05:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      " Schema: _c0, Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/aRKNitro/Tutorials/Datasets/Sales%20Data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+--------------------+----------------+----------+----------+--------------------+-----+------+--------------+----+\n",
      "| _c0|Order ID|             Product|Quantity Ordered|Price Each|Order Date|    Purchase Address|Month| Sales|          City|Hour|\n",
      "+----+--------+--------------------+----------------+----------+----------+--------------------+-----+------+--------------+----+\n",
      "| 297|  295941|     ThinkPad Laptop|               1|    999.99|2019-12-31|64 Dogwood St, Po...|   12|999.99|      Portland|  16|\n",
      "| 464|  296105|Lightning Chargin...|               1|     14.95|2019-12-29|134 Dogwood St, S...|   12| 14.95| San Francisco|  17|\n",
      "| 532|  296169|              iPhone|               1|     700.0|2019-12-10|111 Hickory St, S...|   12| 700.0|       Seattle|  22|\n",
      "| 628|  296263|    Wired Headphones|               1|     11.99|2019-12-11|229 Pine St, San ...|   12| 11.99| San Francisco|  18|\n",
      "| 721|  296351|     ThinkPad Laptop|               1|    999.99|2019-12-24|168 10th St, Port...|   12|999.99|      Portland|  17|\n",
      "|1203|  296811|34in Ultrawide Mo...|               1|    379.99|2019-12-10|485 11th St, Port...|   12|379.99|      Portland|   7|\n",
      "|1395|  296992|Apple Airpods Hea...|               1|     150.0|2019-12-09|410 Washington St...|   12| 150.0|        Dallas|  18|\n",
      "|1414|  297009|  Macbook Pro Laptop|               1|    1700.0|2019-12-16|779 Maple St, San...|   12|1700.0| San Francisco|   8|\n",
      "|1431|  297025|34in Ultrawide Mo...|               1|    379.99|2019-12-18|836 Forest St, Bo...|   12|379.99|        Boston|  12|\n",
      "|1670|  297251|              iPhone|               1|     700.0|2019-12-19|835 Main St, Aust...|   12| 700.0|        Austin|  20|\n",
      "|1782|  297356|27in 4K Gaming Mo...|               1|    389.99|2019-12-18|769 14th St, Dall...|   12|389.99|        Dallas|  22|\n",
      "|1982|  297548|USB-C Charging Cable|               1|     11.95|2019-12-27|24 Pine St, New Y...|   12| 11.95| New York City|  23|\n",
      "|2037|  297596|       Flatscreen TV|               1|     300.0|2019-12-10|301 13th St, Los ...|   12| 300.0|   Los Angeles|  18|\n",
      "|2563|  298104|AA Batteries (4-p...|               1|      3.84|2019-12-16|955 Johnson St, L...|   12|  3.84|   Los Angeles|  22|\n",
      "|2746|  298285|Lightning Chargin...|               1|     14.95|2019-12-21|966 Lincoln St, S...|   12| 14.95| San Francisco|  12|\n",
      "|2887|  298422|Lightning Chargin...|               1|     14.95|2019-12-19|249 Wilson St, Da...|   12| 14.95|        Dallas|  20|\n",
      "|3431|  298934|    Wired Headphones|               1|     11.99|2019-12-11|400 Highland St, ...|   12| 11.99|       Seattle|  10|\n",
      "|3469|  298972|    Wired Headphones|               1|     11.99|2019-12-06|80 Elm St, Los An...|   12| 11.99|   Los Angeles|  14|\n",
      "|4135|  299597|Bose SoundSport H...|               1|     99.99|2019-12-05|606 Willow St, Ne...|   12| 99.99| New York City|  10|\n",
      "|4244|  299700|AA Batteries (4-p...|               1|      3.84|2019-12-20|371 Cedar St, Dal...|   12|  3.84|        Dallas|   6|\n",
      "+----+--------+--------------------+----------------+----------+----------+--------------------+-----+------+--------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "81d4be0d-c8f6-432f-be80-8ff023875aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter((col(\"Sales\") >= 0) & (col(\"Price Each\") >= 0) & (col(\"Quantity Ordered\") >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fea25752-0040-461b-9537-61c91417e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sales = df.groupBy(\"Product\").agg(sum(\"Sales\").alias(\"Total Sales\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9ff6c9cf-6b61-4584-86af-d56b9b5ffd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 06:09:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      " Schema: _c0, Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/aRKNitro/Tutorials/Datasets/Sales%20Data.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             Product|       Total Sales|\n",
      "+--------------------+------------------+\n",
      "|    Wired Headphones| 246651.9337599966|\n",
      "|  Macbook Pro Laptop|         8037600.0|\n",
      "|Apple Airpods Hea...|         2349150.0|\n",
      "|              iPhone|         4794300.0|\n",
      "|Lightning Chargin...| 347094.1500000096|\n",
      "|Bose SoundSport H...|1345565.4300000193|\n",
      "|USB-C Charging Cable|286674.79376000474|\n",
      "|AAA Batteries (4-...| 92740.82999999715|\n",
      "|        20in Monitor|  454148.710000002|\n",
      "|    27in FHD Monitor| 1132424.500000006|\n",
      "|     Vareebadd Phone|          827200.0|\n",
      "|34in Ultrawide Mo...| 2355558.009999994|\n",
      "|            LG Dryer|          387600.0|\n",
      "|AA Batteries (4-p...|106300.05375999837|\n",
      "|        Google Phone|         3319200.0|\n",
      "|       Flatscreen TV|         1445700.0|\n",
      "|  LG Washing Machine|          399600.0|\n",
      "|27in 4K Gaming Mo...| 2435097.559999993|\n",
      "|     ThinkPad Laptop|4129958.6999999806|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a4a74e27-679c-447b-acfb-39d9daad9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"Datasets/output/Sales_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fb528436-a029-4373-be19-9678f951a2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/30 06:11:27 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      " Schema: _c0, Order ID, Product, Quantity Ordered, Price Each, Order Date, Purchase Address, Month, Sales, City, Hour\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/aRKNitro/Tutorials/Datasets/Sales%20Data.csv\n",
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df.write.csv(output_path, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17837287-3077-4185-a839-6b5a77bdcf88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
